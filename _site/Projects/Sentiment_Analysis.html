<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css" rel="stylesheet" id="bootstrap-css">
<script src="//code.jquery.com/jquery-1.11.1.min.js"></script>
<link rel="stylesheet" type="text/css" href="../css/nav.css">
 <link rel="stylesheet" href="../css/blog.css">   
  <link href="https://fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet">
<meta name="theme-color" content="#22114ee0" />

<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js"></script>
<link rel="stylesheet" type="text/css" href="../css/tango.css">
<!------ Include the above in your HEAD tag ---------->

  <div id="wrapper">
        <div class="overlay"></div>
    
        <!-- Sidebar -->
     <nav class="navbar navbar-inverse navbar-fixed-top" id="sidebar-wrapper" role="navigation">
            <ul class="nav sidebar-nav">
               <li class="" style="
    text-align: center;
    background: #000000;
"> 
                 <img src="https://scontent.fbho1-1.fna.fbcdn.net/v/t1.0-1/p160x160/24176670_1494666630649404_7505247795837322239_n.jpg?_nc_cat=0&amp;oh=8b160fed68b34d89bfa5587f3fc6d403&amp;oe=5B32B2C8" style="
    border-radius: 200px;
    height: 100px;
    width: 100px;
    margin: 14% auto;
    padding: 9px;
    border: 1px double #664e90;
">
        
                </li>
                <li class="sidebar-brand">
                    <a href="#">
                       Ankit Mishra
                    </a>
                </li>
                <li>
                    <a href="https://ankitpyc.github.io/">Home</a>
		    </li>
                <li>
                    <a href="https://ankitpyc.github.io/Projects">Profile</a>
                </li>
                <li>
                   <a href="https://ankitpyc.github.io/About">About</a> 
                </li>
                <li>
                    <a href="#">Contact me</a>
                </li>
                <li>
                    <a href="https://twitter.com/maridlcrmn">Follow me</a>
                </li>
            </ul>
            <div style="height: 10%;
    text-align: center;
    width: 100%;
    position: absolute;
    bottom: 0px;
    align-items: center;
    display: flex;
    color: white !important;
    justify-content: space-around;" class="footer-nav">
                <a href=""><i class="fa fa-1x fa-github"></i></a>
                <a href=""><i class="fa fa-1x fa-facebook"></i></a>
                <a href=""> <i class="fa fa-1x fa-gmail"></i> </a>
            </div>
        </nav>
        <!-- /#sidebar-wrapper -->

        <!-- Page Content -->
        <div id="page-content-wrapper">
            <button type="button" class="hamburger is-closed" data-toggle="offcanvas">
                <span class="hamb-top"></span>
                <span class="hamb-middle"></span>
                <span class="hamb-bottom"></span>
            </button>
            <div class="container-fluid">
                <div class="row">
                    <div style="padding: 0px;" class="col-lg-12">
                       <div  class="image_overrelay">
<div class="heading_container">
  <h1 class="project_heading">Movie Reviews Sentiment Analysis Using Machine Learning
</h1>
</div>
<img class="image-banner" src="http://www.5wpr.com/new/wp-content/uploads/2016/03/sentiment-analysis-public-relations.jpg">  

</div>
                   
                    </div>
                </div>
                 <div class="row">
                    <div class="col-md-8 col-md-offset-2 col-sm-8 col-md-offset-2 col-xs-12 ">
<div class="skills">skills : Natural Language Processing,Sklearn,python,Random Forest,Naive Bayes
</div>

<hr>
<h2>About the Project</h2>
<p>In this Project we will be building a Sentiment Analyzer that will be used to judge sentiment of movie reviews.</p>
The dataset has been taken from the rotten tomatoes website.We will be dealing will Natural language processing in python and will be sung several modules of python for NLP.This notebook aims at cleaning data as we are dealing with raw reviews.Lets start
<h2>Exploration and Analysis</h2>
<p>Lets import our libraries</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span></code></pre></figure>        

<p>we are having only one data file <code>train.tsv</code> . Now tsv(tab seprate values) are another extension of data files just like .xls or .csv. Pandas has a special function read_table which allows us to deal with these files/<p>

<p>lets see what we have in these files</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span>  <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s">'train.tsv'</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  </code></pre></figure>      

<table style="overflow-x:scroll;"  border="1" class="table table-responsive">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PhraseId</th>
      <th>SentenceId</th>
      <th>Phrase</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>A series</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>A</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
      <td>series</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>The Phrase has all the Sentiments of the reviews.The reviews have been parsed by the stanford parser and split into sentences. Each review has a <code>sentence id</code> and a <code>phrase id</code>.
</p>

<p> Now if we observe the sentiments columns we have multiclass labels to sentiments.sentiments have 0,1,2,3,4 numeric classes.Tne dataset source stated that what each numeric label meant so </p>

<p>
<code>0 </code> : Negative <br>   
<code>1 </code> : Somewhat Negative <br>
<code>2 </code> : Neutral <br>
<code>3 </code> : Positive <br>
<code>4 </code> : Somewhat Postive <br>
</p>

<p>For visualization purpose lets convert the numeric columns to categorical.Lets write a method to convert each row of pandas dataframe to numerical</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">num_sen</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"negative"</span>
    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"somewhat negative"</span>
    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"neutral"</span>
    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">3</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"positive"</span>
    <span class="k">if</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="mi">4</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"somewhat positive"</span>        </code></pre></figure>          

<p>Now we will analyze the distribution of various sentiments of dataset</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s">'Sentiment'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Sentiment'</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">num_sen</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">Sentiment</span><span class="p">)</span></code></pre></figure>        


<img src="../static_assets/Sentiment Analysis/count.png" alt="">


<p>Looks like we have a lot of samples belonging to neutral class :-).People try to be Diplomatic in film reviews</p>

<hr>

<h2>Positive Sentiments Analysis</h2>

<p>In this Section we will focus only on the Positive Sentiments from the dataset.We will breakdown sentiments into words,Clean the data and visualize.</p>

<p>Lets extract the positive sentiments out of the Sentiments column </p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df_sentiments</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Sentiment'</span><span class="p">]</span> <span class="o">==</span> <span class="s">"positive"</span><span class="p">]</span></code></pre></figure>        

<p>Now we will split each sentence into tokens of words.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">positive</span> <span class="o">=</span> <span class="n">df_sentiments</span><span class="p">[</span><span class="s">'Phrase'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">))</span></code></pre></figure>   


<p>After this we will count the words which occur in positive sentiments and their counts.this will help us understand what positive sentence mainly comprises of and what do we actually have in them.</p>     


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">positive_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">positive</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">positive_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">positive_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">positive_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span></code></pre></figure>  

<p>Framing the results into dataset for visualization.</p>      

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">positive_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span><span class="n">positive_dict</span><span class="p">[</span><span class="n">x</span><span class="p">]]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">positive_dict</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'word'</span><span class="p">,</span><span class="s">'count'</span><span class="p">])</span></code></pre></figure>

<p>Lets do a barplot</p>
<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">positive_counts</span><span class="p">[</span><span class="s">'word'</span><span class="p">][:</span><span class="mi">100</span><span class="p">],</span><span class="n">x</span><span class="o">=</span><span class="n">positive_counts</span><span class="p">[</span><span class="s">'count'</span><span class="p">][:</span><span class="mi">100</span><span class="p">])</span></code></pre></figure>        

<img src="../static_assets/Sentiment Analysis/positive_count.png" alt="">

<p>It seems like the most common word or element or token is <code>,</code> followed by <code>the</code> and other 
<b>articles</b>,<b>pos(parts of speech)</b>.It seems pretty obvious because these comprises of most of what we speak in daily life. <code>The</code> and <code>and</code> are the most common words in English Sentences.
</p>

<p>But regarding building predictive model for sentiments analysis these wont play a special role as they would be common to all sentences.</p>

<h3>Cleaning the Positive reviews</h3>

<p>Now its time to gear up and clean our reviews. we have seen in above visualization that these are prominent in our reviews and don't play much important role.we would be cleaning reviews using the python Natural Language Processing library <code>NLTK</code></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">nltk.stem.wordnet</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">))</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s">'wordnet'</span><span class="p">)</span></code></pre></figure>        

<p>we have imported stopwords Stemmer Lemmatizer and downloaded the wordnet for Lemmatizer.we will see what each of these are and how they will clean our reviews</p>

<ul>
    <li>
        <b>Stopwords Punctuations and special characters</b>
        <p>Stopwords are words which are very repetitive and useless.These words means nothing, unless of course we're searching for someone who is maybe lacking confidence, is confused, or hasn't practiced much speaking. We all do it, you can hear me saying "umm" or "uhh" </p>


    </li>
    <li> <b>Stemming</b>
        <p>Stemming is the process of reducing a word into its stem, i.e. its root form.root form of eating is eat,sleeping is sleep.converting words to roots reduces ambiguity in  sentences</p>
    </li>
    <li><b>Lemmatizing</b>
        <p>Lemmatization is somewhat similar to stemming but it maps several different words to a common root</p>
        <p>for eg: go,going,went are mapped to go</p>
    </li>
</ul>

<p>Now we will write a function that does this for us . Since Both Stemming and Lemmatization reduces words into their root forms , any one can be used.I will be using Lemmatization in this Notebook.we will also use python inbuilt regular expression library <code>re</code> for removing symbols and special characters and Numbers.</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">re</span>
<span class="c"># lets define a function that does this </span>
<span class="k">def</span> <span class="nf">clean_reviews</span><span class="p">(</span><span class="n">review</span><span class="p">):</span>
    <span class="c"># removing the punctuation and special symbols</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'[^A-Za-z]+'</span><span class="p">,</span><span class="s">' '</span><span class="p">,</span><span class="n">review</span><span class="p">)</span>
    <span class="c"># converting words to lowercase</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c"># converting sentences to list of words</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
    <span class="c"># removing the stop words</span>
    <span class="n">review_cleaned</span>  <span class="o">=</span> <span class="p">[</span><span class="n">words</span> <span class="k">for</span> <span class="n">words</span>  <span class="ow">in</span> <span class="n">review</span> <span class="k">if</span> <span class="n">words</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)]</span> 
    <span class="c"># Stemming</span>
    <span class="k">if</span><span class="p">(</span><span class="ow">not</span><span class="p">(</span><span class="n">Lemma</span><span class="p">)):</span>
        <span class="c">#stemming words so that we can get into the root word</span>
        <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
        <span class="n">review_cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">review_cleaned</span><span class="p">]</span>
        <span class="k">return</span> <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">words</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">review_cleaned</span><span class="p">])</span>
    <span class="c">#Lemmatizing</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
        <span class="n">review_cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="n">Lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">review_cleaned</span><span class="p">]</span>
        <span class="n">rev</span> <span class="o">=</span>  <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">words</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">review_cleaned</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">rev</span></code></pre></figure>        

<p>The above function processes each of the raw positive raw reviews it the data and return the cleaned review.we have set <code>Lemma = 1</code>so that i could easily switch using the same function</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Lemma</span> <span class="o">=</span> <span class="mi">1</span></code></pre></figure>        

<p>Now lets gets the things done!!</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s">'cleaned_reviews'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Phrase'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">clean_reviews</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s">'cleaned_reviews'</span><span class="p">]</span></code></pre></figure>        
<pre class="output">
 0         series escapade demonstrating adage good goose...
1            series escapade demonstrating adage good goose
2                                                    series
3                                                          
4                                                    series
5                   escapade demonstrating adage good goose
6                                                          
7                   escapade demonstrating adage good goose
8                                                  escapade
9                            demonstrating adage good goose
10                                      demonstrating adage
11                                            demonstrating
12                                                    adage
13                                                         
14                                                    adage
15                                               good goose
16                                                         
17                                               good goose
18                                                         
19                                               good goose
20                                                         
21                                               good goose
22                                                     good
23                                                    goose
24                                                         
25                                                    goose
26                                                    goose
27        also good gander occasionally amuses none amou...
28        also good gander occasionally amuses none amou...
29                                          
 upto no of postive reviews
</pre>



<p>Now we have seen how will be dealing with raw reviews,Lets apply it to the whole sentiments data.</p>
<hr>
<h2>Sentiment Analysis and Predictive Modeling</h2>

<p>Now lets clean all the reviews by applying the <code>clean_reviews</code> to all sentiments and create a new column  in the dataframe 'cleaned_reviews'</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s">'cleaned_reviews'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Phrase'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">clean_reviews</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s">'cleaned_reviews'</span><span class="p">]</span></code></pre></figure>        

<p>It takes some 3-5 minutes to process as it has 1,50,000 reviews.Now we will be using our cleaned reviews as feature and start building our predictive model using various NLP techniques</p>

<hr>

<h2>NLP Methods for Text Analysis</h2>
In Natural Language Processing there are several techniques or methods to analyze text data.some of the famous algorithms are <code>Bag of Words</code>,<code>TfIdf(Term Frequency Inverse Document Frequency)</code> and <code>Word2vec</code>.We will be using Bag of Words and Tfidf for Feature Extraction.Lets see both of the algorithms.

<h3>Bag of Words</h3>
<p>
The bag-of-words model is a way of representing text data when modeling text with machine learning algorithms.

The bag-of-words model is simple to understand and implement and has seen great success in problems such as language modeling and document classification.</p>
<h3>TFIDF</h3>
<p>TFIDF(Term frequency inverse document frequency) is also one of the techniques for dealing with text data.In Bag of Words model,we simply count the occurrence of words and simply write the count at a particular index in the feature vector . But since we are only using count , words which are rare in the reviews will have less impact on predicting the sentiment . TFIDF measures the number of times that words appear in a given document(Term Frequency).The Idf term is the total occurrence of a word in all documents to total no of documents in the dataset.</p>
<img src="https://deeplearning4j.org/img/tfidf.png" alt="">

<p>Now we will be building a sklearn pipeline to use both the Bag of Words and Tfidf to calculate feature vectors</p>
<hr>
<h2>Building a Sentiment Classifier</h2>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.pipleline</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span>  <span class="kn">import</span> <span class="n">Tfidf</span><span class="p">,</span><span class="n">CountVectorizer</span></code></pre></figure>        

<p> <code>TfIdf</code> and <code>CountVectorizer</code> are the sklearn implementation of Tfidf and Bag of Words implementation of sklearn. </p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">BOW</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">BOW_Features</span> <span class="o">=</span> <span class="n">BOW</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="s">'cleaned_reviews'</span><span class="p">]))</span> </code></pre></figure>     

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">BOW_Features</span></code></pre></figure>

<pre class="output">
<156060x5000 sparse matrix of type '<type 'numpy.int64'>'with 524767 stored elements in Compressed Sparse Row format>
</pre>

<p>We have got a sparse matrix of 156000x5000 where each row corresponds to a single document and a feature vector of 5000 features. <code>CountVectorizer</code> allows us choose an arbitrary size of feature vector</p>

<p>Now we will fit a TfIdf vectorizer on the bag of words feature</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tfidf</span> <span class="o">=</span> <span class="n">Tfidf</span><span class="p">()</span>
<span class="n">tfidf_features</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">max_features</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span>
<span class="n">tfidf_features</span></code></pre></figure>
<pre class="output">
<156060x2000 sparse matrix of type '<type 'numpy.float64'>'with 419006 stored elements in Compressed Sparse Row format> 
</pre>        

<p>Now we will train a naive Bayes classifier for sentiment analysis.Naive Bayes is very popular for text classification and is used popularly.</p>
<hr>
<h2>Train Test Split</h2>

<p>We will split our whole tfidf sparse matrix into train and test using sklearn's <code>train_test_split</code></p>
<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">tfidf_features</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Sentiment'</span><span class="p">],</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code></pre></figure>        
<p>Lets train our model on Multinomial Naive Bayes which is used for Multi classification Problem.</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">model_naive</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">model_naive</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span></code></pre></figure>        

<p>Now lets predict the values in the test set and see its accuracy</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">predictions</span> <span class="o">=</span> <span class="n">model_naive</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span></code></pre></figure>        
<pre class="output">
0.562
</pre>
<p>Its seems like we have achieved a good accuracy better than random guessing.Naive Bayes is not performing that well in sentiment analysis.</p>
<hr>
<h2>Random Forest Classifier</h2>

<p>As we have seen naive Bayes is not giving better predictions,Lets use random forest an ensemble of Decision Trees.</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">model_randomf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model_randomf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span></code></pre></figure>        

<p>Lets check the predictions and accuracy of our random forest model.</p>


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">predictions</span> <span class="o">=</span> <span class="n">model_randomf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span> <span class="s">"accuracy :"</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span></code></pre></figure>        
<pre class="output">
accuracy : 0.6189708737864078
</pre>
<p>Whoo ! a 5% increment in accuracy using random forest.we have improved our model performance significantly using random forest.</p>

<hr>
<h2>Predictions on Raw reviews</h2>

At last we come to this section where we will be using random tweets of movie reviews to judge our model performance and to check whether our model generalizes over real data or not.


</div>



</div>

<hr>
<div style="text-align: center;
    font-size: medium;">
Thankyou for reading !!
<div >
<div style="
    display: flex;
    align-items: center;
    justify-content: center;
">
<i style="text-align: center;
    margin: 1%;
    padding: 9px 10px;
    border: 1px solid #dfdfdf;
    border-radius: 200px;" class="fa fa-1x fa-github"></i>	
<i style="text-align: center;
    margin: 1%;
    padding: 9px 10px;
    border: 1px solid #dfdfdf;
    border-radius: 200px;" class="fa fa-1x fa-facebook"></i>
<i style="text-align: center;
    margin: 1%;
    padding: 9px 10px;
    border: 1px solid #dfdfdf;
    border-radius: 200px;" class="fa fa-1x fa-quora"></i>
</div>
</div>
</div>
            </div>
        </div>
        <!-- /#page-content-wrapper -->

    </div>
<script src="../css/blog.js" type="text/javascript"></script>
</body>
</html>
